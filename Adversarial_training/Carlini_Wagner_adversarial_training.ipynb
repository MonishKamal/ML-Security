{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b1588c2-91c3-40c2-b710-ff43ddbca874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from cleverhans.torch.attacks.carlini_wagner_l2 import carlini_wagner_l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8280e64e-852f-4ac8-8363-6a47b63cb3a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load FashionMNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "train_loader = DataLoader(\n",
    "    datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform),\n",
    "    batch_size=1000, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39cc79f5-d3f3-4ac9-8541-2a1bff5d4d02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a ResNet50 model adapted for grayscale images and 10 classes\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.model = models.resnet50(weights=None)\n",
    "        # Modify the first conv layer to accept 1-channel input\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        # Remove maxpool layer to reduce spatial downsampling\n",
    "        self.model.maxpool = nn.Identity()\n",
    "        # Modify the fully connected layer to output 10 classes\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = ResNet50().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training function with CW-L2 adversarial examples\n",
    "def train_with_cw(model, train_loader, optimizer, criterion, device, epoch):\n",
    "    model.train()\n",
    "    total_loss, total_adv_loss = 0, 0\n",
    "    correct, correct_adv = 0, 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Standard forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Compute accuracy for clean data\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        # Generate adversarial examples using CW-L2 from CleverHans\n",
    "        adv_data = carlini_wagner_l2(model, data, n_classes=10, targeted=False, confidence=0, clip_min=0.0, clip_max=1.0, max_iterations=10)\n",
    "        \n",
    "        # Forward pass on adversarial examples\n",
    "        adv_output = model(adv_data)\n",
    "        adv_loss = criterion(adv_output, target)\n",
    "        total_adv_loss += adv_loss.item()\n",
    "\n",
    "        # Compute accuracy for adversarial data\n",
    "        adv_pred = adv_output.argmax(dim=1, keepdim=True)\n",
    "        correct_adv += adv_pred.eq(target.view_as(adv_pred)).sum().item()\n",
    "\n",
    "        # Combined loss\n",
    "        total_batch_loss = (loss + adv_loss) / 2\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        total_batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += target.size(0)\n",
    "\n",
    "        # Log information for each batch\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch: {epoch+1} [{batch_idx * len(data)}/{len(train_loader.dataset)}] '\n",
    "                  f'Loss: {loss.item():.4f} | Adv Loss: {adv_loss.item():.4f} | '\n",
    "                  f'Acc: {100. * correct / total:.2f}% | Adv Acc: {100. * correct_adv / total:.2f}%')\n",
    "\n",
    "    # Log average loss and accuracy for epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_adv_loss = total_adv_loss / len(train_loader)\n",
    "    avg_acc = 100. * correct / total\n",
    "    avg_adv_acc = 100. * correct_adv / total\n",
    "    print(f'==> Epoch: {epoch+1} | Avg Loss: {avg_loss:.4f} | Avg Adv Loss: {avg_adv_loss:.4f} | '\n",
    "          f'Avg Acc: {avg_acc:.2f}% | Avg Adv Acc: {avg_adv_acc:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "423e939e-f117-4782-a00c-9dbdcb183de0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 [0/60000] Loss: 2.3446 | Adv Loss: 2.3619 | Acc: 15.62% | Adv Acc: 6.25%\n",
      "Epoch: 1 [6400/60000] Loss: 12.2217 | Adv Loss: 12.1206 | Acc: 9.03% | Adv Acc: 9.50%\n",
      "Epoch: 1 [12800/60000] Loss: 11.7812 | Adv Loss: 11.8770 | Acc: 9.28% | Adv Acc: 9.72%\n",
      "Epoch: 1 [19200/60000] Loss: 10.5922 | Adv Loss: 10.8280 | Acc: 9.92% | Adv Acc: 10.10%\n",
      "Epoch: 1 [25600/60000] Loss: 11.9562 | Adv Loss: 11.9950 | Acc: 10.27% | Adv Acc: 9.91%\n",
      "Epoch: 1 [32000/60000] Loss: 19.1488 | Adv Loss: 19.0997 | Acc: 10.15% | Adv Acc: 10.08%\n",
      "Epoch: 1 [38400/60000] Loss: 16.1204 | Adv Loss: 16.4417 | Acc: 9.98% | Adv Acc: 9.95%\n",
      "Epoch: 1 [44800/60000] Loss: 21.0035 | Adv Loss: 20.8643 | Acc: 9.92% | Adv Acc: 9.94%\n",
      "Epoch: 1 [51200/60000] Loss: 23.5379 | Adv Loss: 20.4228 | Acc: 9.94% | Adv Acc: 9.98%\n",
      "Epoch: 1 [57600/60000] Loss: 48.4336 | Adv Loss: 49.6084 | Acc: 9.75% | Adv Acc: 9.87%\n",
      "==> Epoch: 1 | Avg Loss: 19.3728 | Avg Adv Loss: 19.2713 | Avg Acc: 9.76% | Avg Adv Acc: 9.84%\n",
      "Epoch 1/5 completed\n",
      "\n",
      "Epoch: 2 [0/60000] Loss: 48.6147 | Adv Loss: 49.4509 | Acc: 12.50% | Adv Acc: 4.69%\n",
      "Epoch: 2 [6400/60000] Loss: 52.9797 | Adv Loss: 49.8971 | Acc: 8.63% | Adv Acc: 9.25%\n",
      "Epoch: 2 [12800/60000] Loss: 43.5854 | Adv Loss: 44.9058 | Acc: 9.27% | Adv Acc: 9.69%\n",
      "Epoch: 2 [19200/60000] Loss: 41.7058 | Adv Loss: 44.7550 | Acc: 9.56% | Adv Acc: 9.90%\n",
      "Epoch: 2 [25600/60000] Loss: 42.4380 | Adv Loss: 44.8821 | Acc: 9.48% | Adv Acc: 9.83%\n",
      "Epoch: 2 [32000/60000] Loss: 36.9199 | Adv Loss: 38.8860 | Acc: 9.71% | Adv Acc: 10.00%\n",
      "Epoch: 2 [38400/60000] Loss: 43.5971 | Adv Loss: 48.2765 | Acc: 9.75% | Adv Acc: 9.91%\n",
      "Epoch: 2 [44800/60000] Loss: 48.2959 | Adv Loss: 48.8755 | Acc: 9.71% | Adv Acc: 9.94%\n",
      "Epoch: 2 [51200/60000] Loss: 46.1236 | Adv Loss: 45.0079 | Acc: 9.78% | Adv Acc: 9.87%\n",
      "Epoch: 2 [57600/60000] Loss: 39.2756 | Adv Loss: 33.2434 | Acc: 9.88% | Adv Acc: 9.91%\n",
      "==> Epoch: 2 | Avg Loss: 44.3367 | Avg Adv Loss: 44.8202 | Avg Acc: 9.85% | Avg Adv Acc: 9.88%\n",
      "Epoch 2/5 completed\n",
      "\n",
      "Epoch: 3 [0/60000] Loss: 37.4653 | Adv Loss: 40.6872 | Acc: 4.69% | Adv Acc: 12.50%\n",
      "Epoch: 3 [6400/60000] Loss: 37.3736 | Adv Loss: 41.9683 | Acc: 10.37% | Adv Acc: 9.58%\n",
      "Epoch: 3 [12800/60000] Loss: 37.3218 | Adv Loss: 35.8746 | Acc: 10.47% | Adv Acc: 9.98%\n",
      "Epoch: 3 [19200/60000] Loss: 41.4174 | Adv Loss: 39.7906 | Acc: 10.50% | Adv Acc: 10.29%\n",
      "Epoch: 3 [25600/60000] Loss: 40.8216 | Adv Loss: 42.1710 | Acc: 10.29% | Adv Acc: 10.25%\n",
      "Epoch: 3 [32000/60000] Loss: 39.8804 | Adv Loss: 38.4076 | Acc: 10.29% | Adv Acc: 10.25%\n",
      "Epoch: 3 [38400/60000] Loss: 34.3772 | Adv Loss: 36.8048 | Acc: 10.18% | Adv Acc: 10.13%\n",
      "Epoch: 3 [44800/60000] Loss: 33.8024 | Adv Loss: 34.9284 | Acc: 10.17% | Adv Acc: 10.05%\n",
      "Epoch: 3 [51200/60000] Loss: 33.3585 | Adv Loss: 37.7572 | Acc: 9.99% | Adv Acc: 9.93%\n",
      "Epoch: 3 [57600/60000] Loss: 37.9890 | Adv Loss: 36.3696 | Acc: 9.85% | Adv Acc: 9.91%\n",
      "==> Epoch: 3 | Avg Loss: 36.9497 | Avg Adv Loss: 37.4712 | Avg Acc: 9.80% | Avg Adv Acc: 9.85%\n",
      "Epoch 3/5 completed\n",
      "\n",
      "Epoch: 4 [0/60000] Loss: 30.5417 | Adv Loss: 34.3705 | Acc: 10.94% | Adv Acc: 14.06%\n",
      "Epoch: 4 [6400/60000] Loss: 29.8219 | Adv Loss: 31.6687 | Acc: 9.16% | Adv Acc: 9.67%\n",
      "Epoch: 4 [12800/60000] Loss: 31.4963 | Adv Loss: 32.8471 | Acc: 9.20% | Adv Acc: 9.77%\n",
      "Epoch: 4 [19200/60000] Loss: 31.2871 | Adv Loss: 31.4133 | Acc: 9.22% | Adv Acc: 9.56%\n",
      "Epoch: 4 [25600/60000] Loss: 34.1316 | Adv Loss: 33.2620 | Acc: 9.24% | Adv Acc: 9.52%\n",
      "Epoch: 4 [32000/60000] Loss: 32.1902 | Adv Loss: 36.9002 | Acc: 9.43% | Adv Acc: 9.70%\n",
      "Epoch: 4 [38400/60000] Loss: 32.6432 | Adv Loss: 30.7601 | Acc: 9.43% | Adv Acc: 9.73%\n",
      "Epoch: 4 [44800/60000] Loss: 25.8458 | Adv Loss: 29.4590 | Acc: 9.53% | Adv Acc: 9.72%\n",
      "Epoch: 4 [51200/60000] Loss: 32.7719 | Adv Loss: 37.9531 | Acc: 9.49% | Adv Acc: 9.69%\n",
      "Epoch: 4 [57600/60000] Loss: 35.8320 | Adv Loss: 36.0456 | Acc: 9.47% | Adv Acc: 9.62%\n",
      "==> Epoch: 4 | Avg Loss: 33.2637 | Avg Adv Loss: 33.9469 | Avg Acc: 9.45% | Avg Adv Acc: 9.57%\n",
      "Epoch 4/5 completed\n",
      "\n",
      "Epoch: 5 [0/60000] Loss: 31.8855 | Adv Loss: 32.8764 | Acc: 12.50% | Adv Acc: 12.50%\n",
      "Epoch: 5 [6400/60000] Loss: 31.5700 | Adv Loss: 33.5355 | Acc: 9.89% | Adv Acc: 10.49%\n",
      "Epoch: 5 [12800/60000] Loss: 32.6881 | Adv Loss: 33.2303 | Acc: 9.69% | Adv Acc: 9.81%\n",
      "Epoch: 5 [19200/60000] Loss: 35.3186 | Adv Loss: 34.4802 | Acc: 9.48% | Adv Acc: 9.46%\n",
      "Epoch: 5 [25600/60000] Loss: 51.2485 | Adv Loss: 50.0873 | Acc: 9.46% | Adv Acc: 9.50%\n",
      "Epoch: 5 [32000/60000] Loss: 50.1546 | Adv Loss: 51.4011 | Acc: 9.51% | Adv Acc: 9.45%\n",
      "Epoch: 5 [38400/60000] Loss: 39.3152 | Adv Loss: 38.0921 | Acc: 9.77% | Adv Acc: 9.61%\n",
      "Epoch: 5 [44800/60000] Loss: 47.2520 | Adv Loss: 46.0359 | Acc: 9.90% | Adv Acc: 9.60%\n",
      "Epoch: 5 [51200/60000] Loss: 46.5528 | Adv Loss: 44.8390 | Acc: 9.92% | Adv Acc: 9.67%\n",
      "Epoch: 5 [57600/60000] Loss: 45.4069 | Adv Loss: 50.5101 | Acc: 9.78% | Adv Acc: 9.64%\n",
      "==> Epoch: 5 | Avg Loss: 41.0562 | Avg Adv Loss: 41.9695 | Avg Acc: 9.77% | Avg Adv Acc: 9.60%\n",
      "Epoch 5/5 completed\n",
      "\n",
      "Adversarial training completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop with CW-L2 adversarial examples\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    train_with_cw(model, train_loader, optimizer, criterion, device, epoch)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} completed\\n\")\n",
    "\n",
    "print(\"Adversarial training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23bc03-c1da-46d9-b384-82924a85e43f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
