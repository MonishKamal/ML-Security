{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfaba4a7",
   "metadata": {},
   "source": [
    "## FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2f75fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load FashionMNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_loader = DataLoader(\n",
    "    datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform),\n",
    "    batch_size=1000, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c1119b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85f1cd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM attack implementation\n",
    "def fgsm_attack(model, data, target, epsilon):\n",
    "    data.requires_grad = True\n",
    "    output = model(data)\n",
    "    loss = F.cross_entropy(output, target)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    data_grad = data.grad.data\n",
    "    perturbed_data = data + epsilon * data_grad.sign()\n",
    "    return perturbed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6569d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial training \n",
    "def train(model, device, train_loader, optimizer, epsilon, epoch):\n",
    "    model.train()\n",
    "    total_loss, total_adv_loss = 0, 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Standard forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Generate adversarial examples using FGSM\n",
    "        adv_data = fgsm_attack(model, data, target, epsilon)\n",
    "        adv_output = model(adv_data)\n",
    "        adv_loss = F.cross_entropy(adv_output, target)\n",
    "        total_adv_loss += adv_loss.item()\n",
    "\n",
    "        # Combined loss\n",
    "        total_batch_loss = (loss + adv_loss) / 2\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        total_batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Log information for each batch\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch: {epoch+1} [{batch_idx * len(data)}/{len(train_loader.dataset)}] '\n",
    "                  f'Loss: {loss.item():.4f} | Adv Loss: {adv_loss.item():.4f}')\n",
    "\n",
    "    # Log average loss for epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_adv_loss = total_adv_loss / len(train_loader)\n",
    "    print(f'==> Epoch: {epoch+1} | Avg Loss: {avg_loss:.4f} | Avg Adv Loss: {avg_adv_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd4797dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "828dd1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a625d96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 [0/60000] Loss: 2.3093 | Adv Loss: 2.3551\n",
      "Epoch: 1 [6400/60000] Loss: 0.5378 | Adv Loss: 0.9141\n",
      "Epoch: 1 [12800/60000] Loss: 0.4797 | Adv Loss: 0.8660\n",
      "Epoch: 1 [19200/60000] Loss: 0.5164 | Adv Loss: 0.8877\n",
      "Epoch: 1 [25600/60000] Loss: 0.2547 | Adv Loss: 0.5873\n",
      "Epoch: 1 [32000/60000] Loss: 0.5033 | Adv Loss: 0.8968\n",
      "Epoch: 1 [38400/60000] Loss: 0.3280 | Adv Loss: 0.6940\n",
      "Epoch: 1 [44800/60000] Loss: 0.4624 | Adv Loss: 0.7919\n",
      "Epoch: 1 [51200/60000] Loss: 0.2020 | Adv Loss: 0.4735\n",
      "Epoch: 1 [57600/60000] Loss: 0.3648 | Adv Loss: 0.7154\n",
      "==> Epoch: 1 | Avg Loss: 0.4065 | Avg Adv Loss: 0.7550\n",
      "Epoch 1/5 completed\n",
      "\n",
      "Epoch: 2 [0/60000] Loss: 0.3102 | Adv Loss: 0.5723\n",
      "Epoch: 2 [6400/60000] Loss: 0.2128 | Adv Loss: 0.4953\n",
      "Epoch: 2 [12800/60000] Loss: 0.3898 | Adv Loss: 0.7472\n",
      "Epoch: 2 [19200/60000] Loss: 0.2632 | Adv Loss: 0.5972\n",
      "Epoch: 2 [25600/60000] Loss: 0.1770 | Adv Loss: 0.4587\n",
      "Epoch: 2 [32000/60000] Loss: 0.3561 | Adv Loss: 0.6687\n",
      "Epoch: 2 [38400/60000] Loss: 0.1922 | Adv Loss: 0.5346\n",
      "Epoch: 2 [44800/60000] Loss: 0.3428 | Adv Loss: 0.6939\n",
      "Epoch: 2 [51200/60000] Loss: 0.2334 | Adv Loss: 0.5733\n",
      "Epoch: 2 [57600/60000] Loss: 0.1948 | Adv Loss: 0.5284\n",
      "==> Epoch: 2 | Avg Loss: 0.2749 | Avg Adv Loss: 0.6093\n",
      "Epoch 2/5 completed\n",
      "\n",
      "Epoch: 3 [0/60000] Loss: 0.3296 | Adv Loss: 0.7723\n",
      "Epoch: 3 [6400/60000] Loss: 0.2357 | Adv Loss: 0.6045\n",
      "Epoch: 3 [12800/60000] Loss: 0.1742 | Adv Loss: 0.5664\n",
      "Epoch: 3 [19200/60000] Loss: 0.1836 | Adv Loss: 0.5703\n",
      "Epoch: 3 [25600/60000] Loss: 0.1990 | Adv Loss: 0.5111\n",
      "Epoch: 3 [32000/60000] Loss: 0.1202 | Adv Loss: 0.4040\n",
      "Epoch: 3 [38400/60000] Loss: 0.1536 | Adv Loss: 0.4247\n",
      "Epoch: 3 [44800/60000] Loss: 0.2619 | Adv Loss: 0.6117\n",
      "Epoch: 3 [51200/60000] Loss: 0.2325 | Adv Loss: 0.5429\n",
      "Epoch: 3 [57600/60000] Loss: 0.3065 | Adv Loss: 0.8145\n",
      "==> Epoch: 3 | Avg Loss: 0.2310 | Avg Adv Loss: 0.5581\n",
      "Epoch 3/5 completed\n",
      "\n",
      "Epoch: 4 [0/60000] Loss: 0.1511 | Adv Loss: 0.4057\n",
      "Epoch: 4 [6400/60000] Loss: 0.1477 | Adv Loss: 0.4343\n",
      "Epoch: 4 [12800/60000] Loss: 0.1517 | Adv Loss: 0.4021\n",
      "Epoch: 4 [19200/60000] Loss: 0.1470 | Adv Loss: 0.4731\n",
      "Epoch: 4 [25600/60000] Loss: 0.3260 | Adv Loss: 0.7113\n",
      "Epoch: 4 [32000/60000] Loss: 0.3441 | Adv Loss: 0.6666\n",
      "Epoch: 4 [38400/60000] Loss: 0.1704 | Adv Loss: 0.4445\n",
      "Epoch: 4 [44800/60000] Loss: 0.1229 | Adv Loss: 0.3588\n",
      "Epoch: 4 [51200/60000] Loss: 0.3305 | Adv Loss: 0.6942\n",
      "Epoch: 4 [57600/60000] Loss: 0.2077 | Adv Loss: 0.5613\n",
      "==> Epoch: 4 | Avg Loss: 0.1961 | Avg Adv Loss: 0.5114\n",
      "Epoch 4/5 completed\n",
      "\n",
      "Epoch: 5 [0/60000] Loss: 0.2086 | Adv Loss: 0.5121\n",
      "Epoch: 5 [6400/60000] Loss: 0.0557 | Adv Loss: 0.3190\n",
      "Epoch: 5 [12800/60000] Loss: 0.1231 | Adv Loss: 0.3442\n",
      "Epoch: 5 [19200/60000] Loss: 0.0915 | Adv Loss: 0.3845\n",
      "Epoch: 5 [25600/60000] Loss: 0.1855 | Adv Loss: 0.4409\n",
      "Epoch: 5 [32000/60000] Loss: 0.1847 | Adv Loss: 0.4803\n",
      "Epoch: 5 [38400/60000] Loss: 0.1228 | Adv Loss: 0.4289\n",
      "Epoch: 5 [44800/60000] Loss: 0.0988 | Adv Loss: 0.3675\n",
      "Epoch: 5 [51200/60000] Loss: 0.1988 | Adv Loss: 0.4475\n",
      "Epoch: 5 [57600/60000] Loss: 0.1263 | Adv Loss: 0.3920\n",
      "==> Epoch: 5 | Avg Loss: 0.1638 | Avg Adv Loss: 0.4645\n",
      "Epoch 5/5 completed\n",
      "\n",
      "Adversarial training completed.\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 5\n",
    "epsilon = 0.1  \n",
    "for epoch in range(epochs):\n",
    "    train(model, device, train_loader, optimizer, epsilon, epoch)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} completed\\n\")\n",
    "\n",
    "print(\"Adversarial training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e67c6",
   "metadata": {},
   "source": [
    "Sp, The decrease in both average losses over epochs suggests the model is improving on both clean and adversarial examples, learning to classify both correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04081312",
   "metadata": {},
   "source": [
    "## CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a852495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83207048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize for 3 channels\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    datasets.CIFAR10(root='./data', train=True, download=True, transform=transform),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    datasets.CIFAR10(root='./data', train=False, download=True, transform=transform),\n",
    "    batch_size=1000, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9784e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a CNN model for CIFAR-10\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)  # 32x32 -> 30x30\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)  # 30x30 -> 28x28\n",
    "        self.fc1 = nn.Linear(12544, 128)  # Flattened size after conv and pooling\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)  # 28x28 -> 14x14\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a030071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM attack implementation\n",
    "def fgsm_attack(model, data, target, epsilon):\n",
    "    data.requires_grad = True\n",
    "    output = model(data)\n",
    "    loss = F.cross_entropy(output, target)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    data_grad = data.grad.data\n",
    "    perturbed_data = data + epsilon * data_grad.sign()\n",
    "    return perturbed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88e0e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial training function with logging\n",
    "def train(model, device, train_loader, optimizer, epsilon, epoch):\n",
    "    model.train()\n",
    "    total_loss, total_adv_loss = 0, 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Standard forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Generate adversarial examples using FGSM\n",
    "        adv_data = fgsm_attack(model, data, target, epsilon)\n",
    "        adv_output = model(adv_data)\n",
    "        adv_loss = F.cross_entropy(adv_output, target)\n",
    "        total_adv_loss += adv_loss.item()\n",
    "\n",
    "        # Combined loss\n",
    "        total_batch_loss = (loss + adv_loss) / 2\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        total_batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Log information for each batch\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch: {epoch+1} [{batch_idx * len(data)}/{len(train_loader.dataset)}] '\n",
    "                  f'Loss: {loss.item():.4f} | Adv Loss: {adv_loss.item():.4f}')\n",
    "\n",
    "    # Log average loss for epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_adv_loss = total_adv_loss / len(train_loader)\n",
    "    print(f'==> Epoch: {epoch+1} | Avg Loss: {avg_loss:.4f} | Avg Adv Loss: {avg_adv_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fe8f2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38c38715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 [0/50000] Loss: 2.3125 | Adv Loss: 2.3902\n",
      "Epoch: 1 [6400/50000] Loss: 1.6778 | Adv Loss: 2.4240\n",
      "Epoch: 1 [12800/50000] Loss: 1.7606 | Adv Loss: 2.6576\n",
      "Epoch: 1 [19200/50000] Loss: 1.5561 | Adv Loss: 2.5461\n",
      "Epoch: 1 [25600/50000] Loss: 1.3406 | Adv Loss: 2.3883\n",
      "Epoch: 1 [32000/50000] Loss: 1.4365 | Adv Loss: 2.6266\n",
      "Epoch: 1 [38400/50000] Loss: 1.3080 | Adv Loss: 2.3696\n",
      "Epoch: 1 [44800/50000] Loss: 1.2193 | Adv Loss: 2.2465\n",
      "==> Epoch: 1 | Avg Loss: 1.4437 | Avg Adv Loss: 2.4187\n",
      "Epoch 1/5 completed\n",
      "\n",
      "Epoch: 2 [0/50000] Loss: 1.3224 | Adv Loss: 2.4332\n",
      "Epoch: 2 [6400/50000] Loss: 1.2740 | Adv Loss: 2.5509\n",
      "Epoch: 2 [12800/50000] Loss: 1.2614 | Adv Loss: 2.4981\n",
      "Epoch: 2 [19200/50000] Loss: 1.0795 | Adv Loss: 2.3307\n",
      "Epoch: 2 [25600/50000] Loss: 1.0522 | Adv Loss: 2.1670\n",
      "Epoch: 2 [32000/50000] Loss: 1.2905 | Adv Loss: 2.3692\n",
      "Epoch: 2 [38400/50000] Loss: 1.1057 | Adv Loss: 2.4354\n",
      "Epoch: 2 [44800/50000] Loss: 1.1933 | Adv Loss: 2.4381\n",
      "==> Epoch: 2 | Avg Loss: 1.1330 | Avg Adv Loss: 2.3731\n",
      "Epoch 2/5 completed\n",
      "\n",
      "Epoch: 3 [0/50000] Loss: 0.9392 | Adv Loss: 2.0413\n",
      "Epoch: 3 [6400/50000] Loss: 1.0543 | Adv Loss: 2.3646\n",
      "Epoch: 3 [12800/50000] Loss: 0.8599 | Adv Loss: 1.9875\n",
      "Epoch: 3 [19200/50000] Loss: 1.0340 | Adv Loss: 2.1731\n",
      "Epoch: 3 [25600/50000] Loss: 0.9244 | Adv Loss: 1.9717\n",
      "Epoch: 3 [32000/50000] Loss: 1.0016 | Adv Loss: 2.0164\n",
      "Epoch: 3 [38400/50000] Loss: 0.8078 | Adv Loss: 1.8642\n",
      "Epoch: 3 [44800/50000] Loss: 0.8893 | Adv Loss: 2.0125\n",
      "==> Epoch: 3 | Avg Loss: 0.9396 | Avg Adv Loss: 2.0819\n",
      "Epoch 3/5 completed\n",
      "\n",
      "Epoch: 4 [0/50000] Loss: 0.8065 | Adv Loss: 1.8050\n",
      "Epoch: 4 [6400/50000] Loss: 0.7049 | Adv Loss: 1.6605\n",
      "Epoch: 4 [12800/50000] Loss: 0.8208 | Adv Loss: 1.6803\n",
      "Epoch: 4 [19200/50000] Loss: 0.7507 | Adv Loss: 1.9804\n",
      "Epoch: 4 [25600/50000] Loss: 0.7948 | Adv Loss: 1.9435\n",
      "Epoch: 4 [32000/50000] Loss: 0.6083 | Adv Loss: 1.6990\n",
      "Epoch: 4 [38400/50000] Loss: 0.7351 | Adv Loss: 1.9105\n",
      "Epoch: 4 [44800/50000] Loss: 0.7041 | Adv Loss: 1.7835\n",
      "==> Epoch: 4 | Avg Loss: 0.7627 | Avg Adv Loss: 1.8040\n",
      "Epoch 4/5 completed\n",
      "\n",
      "Epoch: 5 [0/50000] Loss: 0.6976 | Adv Loss: 1.7542\n",
      "Epoch: 5 [6400/50000] Loss: 0.6457 | Adv Loss: 1.9115\n",
      "Epoch: 5 [12800/50000] Loss: 0.4119 | Adv Loss: 1.4371\n",
      "Epoch: 5 [19200/50000] Loss: 0.6123 | Adv Loss: 1.4690\n",
      "Epoch: 5 [25600/50000] Loss: 0.4957 | Adv Loss: 1.3564\n",
      "Epoch: 5 [32000/50000] Loss: 0.7191 | Adv Loss: 1.8163\n",
      "Epoch: 5 [38400/50000] Loss: 0.5826 | Adv Loss: 1.5968\n",
      "Epoch: 5 [44800/50000] Loss: 0.7152 | Adv Loss: 1.4637\n",
      "==> Epoch: 5 | Avg Loss: 0.6165 | Avg Adv Loss: 1.6208\n",
      "Epoch 5/5 completed\n",
      "\n",
      "Adversarial training completed.\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 5\n",
    "epsilon = 0.1  # Strength of the adversarial perturbation\n",
    "for epoch in range(epochs):\n",
    "    train(model, device, train_loader, optimizer, epsilon, epoch)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} completed\\n\")\n",
    "\n",
    "print(\"Adversarial training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b57ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fed",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
